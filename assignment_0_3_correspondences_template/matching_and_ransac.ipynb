{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3: Matching, RANSAC and integration\n",
    "This is a notebook, which could help you with testing fourth lab assignment.\n",
    "It contains utility functions for visualization, some test input for the functions you needs to implement,\n",
    "and the output of the reference solution for the same test input.\n",
    "\n",
    "template functions for the assignment contain a short description of what the function is supposed to do,\n",
    "and produce an incorrect output, which is nevertheless in proper format: type and shape.\n",
    "\n",
    "You are not allowed to use kornia or opencv or any other library functions, which are specifically designed\n",
    "to perform the operations requested in assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T14:56:59.335719700Z",
     "start_time": "2024-03-19T14:56:55.939779500Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import kornia\n",
    "import cv2\n",
    "\n",
    "\n",
    "def plot_torch(x, y, *kwargs):\n",
    "    plt.plot(x.detach().cpu().numpy(), y.detach().cpu().numpy(), *kwargs)\n",
    "    return\n",
    "\n",
    "def imshow_torch(tensor,figsize=(8,6), *kwargs):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(kornia.tensor_to_image(tensor), *kwargs)\n",
    "    return\n",
    "\n",
    "def imshow_torch_channels(tensor, dim = 1, *kwargs):\n",
    "    num_ch = tensor.size(dim)\n",
    "    fig=plt.figure(figsize=(num_ch*5,5))\n",
    "    tensor_splitted = torch.split(tensor, 1, dim=dim)\n",
    "    for i in range(num_ch):\n",
    "        fig.add_subplot(1, num_ch, i+1)\n",
    "        plt.imshow(kornia.tensor_to_image(tensor_splitted[i].squeeze(dim)), *kwargs)\n",
    "    return\n",
    "\n",
    "def timg_load(fname, to_gray = True):\n",
    "    img = cv2.imread(fname)\n",
    "    with torch.no_grad():\n",
    "        timg = kornia.image_to_tensor(img, False).float()\n",
    "        if to_gray:\n",
    "            timg = kornia.color.bgr_to_grayscale(timg)\n",
    "        else:\n",
    "            timg = kornia.color.bgr_to_rgb(timg)\n",
    "    return timg\n",
    "\n",
    "\n",
    "def keypoint_locations_to_opencv_kps(keypoint_locations, increase_scale=1.0):\n",
    "    kpts = [cv2.KeyPoint(b_ch_sc_y_x[4].item(),\n",
    "                         b_ch_sc_y_x[3].item(),\n",
    "                         b_ch_sc_y_x[2].item()*increase_scale)\n",
    "            for b_ch_sc_y_x in keypoint_locations if b_ch_sc_y_x[0].item() == 0]\n",
    "    return kpts\n",
    "\n",
    "def visualize_detections(img, keypoint_locations, img_idx = 0, increase_scale = 1.):\n",
    "    # Select keypoints relevant to image   \n",
    "    kpts = keypoint_locations_to_opencv_kps(keypoint_locations, increase_scale)\n",
    "    vis_img = None\n",
    "    vis_img = cv2.drawKeypoints(kornia.tensor_to_image(img).astype(np.uint8),\n",
    "                                kpts,\n",
    "                                vis_img, \n",
    "                                flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    plt.figure(figsize=(12,10))\n",
    "    plt.imshow(vis_img)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T14:56:59.343266Z",
     "start_time": "2024-03-19T14:56:59.338255300Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T14:56:59.667888100Z",
     "start_time": "2024-03-19T14:56:59.342267400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  1.0000],\n",
      "        [ 1.0000,  1.0000],\n",
      "        [-1.0000,  1.0000],\n",
      "        [ 0.0000,  0.5000]])\n",
      "tensor([[ 3.0000,  3.0000],\n",
      "        [ 5.0000,  5.0000],\n",
      "        [ 0.0000,  1.0000],\n",
      "        [ 1.0000,  1.0000],\n",
      "        [-1.0000,  1.0000],\n",
      "        [ 0.0000,  0.5000],\n",
      "        [ 2.0000,  2.0000]])\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 800x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "v1 = torch.tensor([[0,1],[1,1], [-1,1], [0,0.5]]).view(-1,2).float()\n",
    "v2 = torch.cat([torch.tensor([[3,3.],[5,5.]]),v1, torch.tensor([[2.,2.]])], dim=0)\n",
    "print (v1)\n",
    "print (v2)\n",
    "desc1=v1\n",
    "desc2=v2\n",
    "distance_matrix = torch.cdist(desc1,desc2)\n",
    "imshow_torch(distance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T14:57:28.290156300Z",
     "start_time": "2024-03-19T14:57:28.168569800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 2],\n",
      "        [1, 3],\n",
      "        [2, 4],\n",
      "        [3, 5]]) tensor([0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "from matching import *\n",
    "\n",
    "match_idxs, vals = match_snn(desc1, desc2, 0.8)\n",
    "print (match_idxs, vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([], size=(0, 2), dtype=torch.int64), tensor([]))"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_snn(torch.ones((10, 2)), torch.ones((10, 2)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T14:58:26.854648900Z",
     "start_time": "2024-03-19T14:58:26.699423Z"
    }
   },
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference example\n",
    "\n",
    "```python\n",
    "from matching import *\n",
    "\n",
    "\n",
    "match_idxs, vals = match_snn(desc1, desc2, 0.8)\n",
    "print (match_idxs, vals)\n",
    "```\n",
    "\n",
    "    tensor([[0, 2],\n",
    "            [1, 3],\n",
    "            [2, 4],\n",
    "            [3, 5]]) tensor([0., 0., 0., 0.])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-19T14:57:00.491493900Z"
    }
   },
   "outputs": [],
   "source": [
    "#And other direction\n",
    "\n",
    "from matching import *\n",
    "\n",
    "desc1=v2\n",
    "desc2=v1\n",
    "\n",
    "match_idxs, vals = match_snn(desc1, desc2, 0.8)\n",
    "print (match_idxs, vals)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference example\n",
    "\n",
    "```python\n",
    "#And other direction\n",
    "\n",
    "from matching import *\n",
    "\n",
    "desc1=v2\n",
    "desc2=v1\n",
    "\n",
    "\n",
    "\n",
    "match_idxs, vals = match_snn(desc1, desc2, 0.8)\n",
    "print (match_idxs, vals)\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "    tensor([[0, 1],\n",
    "            [2, 0],\n",
    "            [3, 1],\n",
    "            [4, 2],\n",
    "            [5, 3],\n",
    "            [6, 1]]) tensor([0.7845, 0.0000, 0.0000, 0.0000, 0.0000, 0.6325])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T14:57:00.497491200Z",
     "start_time": "2024-03-19T14:57:00.494490600Z"
    }
   },
   "outputs": [],
   "source": [
    "def detect_and_describe(img,\n",
    "                        det='harris',\n",
    "                        th=0.00001,\n",
    "                        affine=False,\n",
    "                        PS = 31):\n",
    "    if det.lower() == 'harris':\n",
    "        keypoint_locations = scalespace_harris(img, th, 20, 1.3)\n",
    "    else:\n",
    "        raise ValueError('Unknown detector, try harris')\n",
    "    n_kp = keypoint_locations.size(0)\n",
    "    A, img_idxs = affine_from_location(keypoint_locations)\n",
    "    if affine:\n",
    "        patches  = extract_affine_patches(img, A, img_idxs, 19, 5.0)\n",
    "        aff_shape = estimate_patch_affine_shape(patches)\n",
    "        dummy_angles = torch.zeros(n_kp,1, dtype=torch.float, device=img.device)\n",
    "                                                          \n",
    "        A, img_idxs = affine_from_location_and_orientation_and_affshape(keypoint_locations, \n",
    "                                                          dummy_angles,\n",
    "                                                          aff_shape)\n",
    "    patches =  extract_affine_patches(img, A, img_idxs, 19, 5.0)\n",
    "    ori = estimate_patch_dominant_orientation(patches)\n",
    "    if affine:\n",
    "        A, img_idxs = affine_from_location_and_orientation_and_affshape(keypoint_locations, \n",
    "                                                  ori,\n",
    "                                                  aff_shape)\n",
    "    else:\n",
    "        A, img_idxs = affine_from_location_and_orientation(keypoint_locations, \n",
    "                                                  ori)\n",
    "    patches =  extract_affine_patches(img, A, img_idxs, PS, 10.0)\n",
    "    descs = calc_sift_descriptor(patches)\n",
    "    return keypoint_locations, descs, A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-19T14:57:00.496494300Z"
    }
   },
   "outputs": [],
   "source": [
    "from local_descriptor import *\n",
    "from local_detector import *\n",
    "from matching import *\n",
    "\n",
    "timg1 = timg_load('v_woman1.ppm', True)/255.\n",
    "timg2 = timg_load('v_woman6.ppm', True)/255.\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    keypoint_locations1, descs1, A1 = detect_and_describe(timg1)\n",
    "    keypoint_locations2, descs2, A2 = detect_and_describe(timg2)\n",
    "    match_idxs, vals = match_snn(descs1, descs2, 0.8)\n",
    "    pts_matches = torch.cat([A1[match_idxs[:,0],:2,2], A2[match_idxs[:,1],:2,2]], dim=1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T14:57:00.510488800Z",
     "start_time": "2024-03-19T14:57:00.498489Z"
    }
   },
   "outputs": [],
   "source": [
    "def tentatives_to_opencv(match_idxs, vals):\n",
    "    tentative_matches = [cv2.DMatch(i[0].item(), i[1].item(), vals[idx].item())\n",
    "                         for idx,i in enumerate(match_idxs)]\n",
    "    return tentative_matches\n",
    "\n",
    "kps1  = keypoint_locations_to_opencv_kps(keypoint_locations1)\n",
    "kps2  = keypoint_locations_to_opencv_kps(keypoint_locations2)\n",
    "\n",
    "match_idxs, vals = match_snn(descs1, descs2, 0.8)\n",
    "tentative_matches = tentatives_to_opencv(match_idxs, vals)\n",
    "\n",
    "\n",
    "img_matches = np.empty((max(timg1.shape[2], timg2.shape[2]), \n",
    "                        timg1.shape[3]+timg2.shape[3], 3), dtype=np.uint8)\n",
    "img1 = (kornia.tensor_to_image(timg1)*255.).astype(np.uint8)\n",
    "img2 = (kornia.tensor_to_image(timg2)*255.).astype(np.uint8)\n",
    "\n",
    "cv2.drawMatches(img1, kps1,\n",
    "                img2, kps2,\n",
    "                tentative_matches, img_matches, \n",
    "                flags=cv2.DrawMatchesFlags_DRAW_RICH_KEYPOINTS)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(img_matches)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Reference example\n",
    "```python\n",
    "def tentatives_to_opencv(match_idxs, vals):\n",
    "    tentative_matches = [cv2.DMatch(i[0].item(), i[1].item(), vals[idx]) for idx,i in enumerate(match_idxs)]\n",
    "    return tentative_matches\n",
    "    \n",
    "kps1  = keypoint_locations_to_opencv_kps(keypoint_locations1)\n",
    "kps2  = keypoint_locations_to_opencv_kps(keypoint_locations2)\n",
    "\n",
    "match_idxs, vals = match_snn(descs1, descs2, 0.8)\n",
    "tentative_matches = tentatives_to_opencv(match_idxs, vals)\n",
    "\n",
    "\n",
    "img_matches = np.empty((max(timg1.shape[2], timg2.shape[2]), \n",
    "                        timg1.shape[3]+timg2.shape[3], 3), dtype=np.uint8)\n",
    "img1 = (kornia.tensor_to_image(timg1)*255.).astype(np.uint8)\n",
    "img2 = (kornia.tensor_to_image(timg2)*255.).astype(np.uint8)\n",
    "\n",
    "cv2.drawMatches(img1, kps1,\n",
    "                img2, kps2,\n",
    "                tentative_matches, img_matches, \n",
    "                flags=cv2.DrawMatchesFlags_DRAW_RICH_KEYPOINTS)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(img_matches)\n",
    "```\n",
    "\n",
    "![image.png](matching_and_ransac_files/att_00000.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-19T14:57:00.500497300Z"
    }
   },
   "outputs": [],
   "source": [
    "def decolorize(img):\n",
    "    return  cv2.cvtColor(cv2.cvtColor(img,cv2.COLOR_RGB2GRAY), cv2.COLOR_GRAY2RGB)\n",
    "def draw_matches(kps1, kps2, tentative_matches, H,  H_gt, inlier_mask, img1, img2):\n",
    "    matchesMask = inlier_mask.ravel().tolist()\n",
    "    h,w, ch = img1.shape\n",
    "    pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "    dst = cv2.perspectiveTransform(pts, H)\n",
    "    #Ground truth transformation\n",
    "    dst_GT = cv2.perspectiveTransform(pts, H_gt)\n",
    "    img2_tr = cv2.polylines(decolorize(img2),[np.int32(dst)],True,(0,0,255),3, cv2.LINE_AA)\n",
    "    img2_tr = cv2.polylines(deepcopy(img2_tr),[np.int32(dst_GT)],True,(0,255,0),3, cv2.LINE_AA)\n",
    "    # Blue is estimated, green is ground truth homography\n",
    "    draw_params = dict(matchColor = (255,255,0), # draw matches in yellow color\n",
    "                   singlePointColor = None,\n",
    "                   matchesMask = matchesMask, # draw only inliers\n",
    "                   flags = 20)\n",
    "    img_out = cv2.drawMatches(decolorize(img1),kps1,img2_tr,kps2,tentative_matches,None,**draw_params)\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(img_out)\n",
    "    return\n",
    "H_gt = np.loadtxt('v_woman_H_1_6')\n",
    "#Geometric verification (RANSAC)\n",
    "from copy import deepcopy\n",
    "def verify(tentative_matches, kps1, kps2):\n",
    "    src_pts = np.float32([ kps1[m.queryIdx].pt for m in tentative_matches ]).reshape(-1,2)\n",
    "    dst_pts = np.float32([ kps2[m.trainIdx].pt for m in tentative_matches ]).reshape(-1,2)\n",
    "    H, inlier_mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,1.0)\n",
    "    return H, inlier_mask\n",
    "    \n",
    "\n",
    "H, inliers =  verify(tentative_matches, kps1, kps2)\n",
    "\n",
    "draw_matches(kps1, kps2, tentative_matches, H, H_gt, inliers, cv2.cvtColor(img1,cv2.COLOR_GRAY2RGB),\n",
    "              cv2.cvtColor(img2,cv2.COLOR_GRAY2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference example\n",
    "\n",
    "```python\n",
    "def decolorize(img):\n",
    "    return  cv2.cvtColor(cv2.cvtColor(img,cv2.COLOR_RGB2GRAY), cv2.COLOR_GRAY2RGB)\n",
    "def draw_matches(kps1, kps2, tentative_matches, H,  H_gt, inlier_mask, img1, img2):\n",
    "    matchesMask = inlier_mask.ravel().tolist()\n",
    "    h,w, ch = img1.shape\n",
    "    pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "    dst = cv2.perspectiveTransform(pts, H)\n",
    "    #Ground truth transformation\n",
    "    dst_GT = cv2.perspectiveTransform(pts, H_gt)\n",
    "    img2_tr = cv2.polylines(decolorize(img2),[np.int32(dst)],True,(0,0,255),3, cv2.LINE_AA)\n",
    "    img2_tr = cv2.polylines(deepcopy(img2_tr),[np.int32(dst_GT)],True,(0,255,0),3, cv2.LINE_AA)\n",
    "    # Blue is estimated, green is ground truth homography\n",
    "    draw_params = dict(matchColor = (255,255,0), # draw matches in yellow color\n",
    "                   singlePointColor = None,\n",
    "                   matchesMask = matchesMask, # draw only inliers\n",
    "                   flags = 20)\n",
    "    img_out = cv2.drawMatches(decolorize(img1),kps1,img2_tr,kps2,tentative_matches,None,**draw_params)\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(img_out)\n",
    "    return\n",
    "H_gt = np.loadtxt('v_woman_H_1_6')\n",
    "#Geometric verification (RANSAC)\n",
    "from copy import deepcopy\n",
    "def verify(tentative_matches, kps1, kps2):\n",
    "    src_pts = np.float32([ kps1[m.queryIdx].pt for m in tentative_matches ]).reshape(-1,2)\n",
    "    dst_pts = np.float32([ kps2[m.trainIdx].pt for m in tentative_matches ]).reshape(-1,2)\n",
    "    H, inlier_mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,1.0)\n",
    "    return H, inlier_mask\n",
    "    \n",
    "\n",
    "H, inliers =  verify(tentative_matches, kps1, kps2)\n",
    "\n",
    "draw_matches(kps1, kps2, tentative_matches, H, H_gt, inliers, cv2.cvtColor(img1,cv2.COLOR_GRAY2RGB),\n",
    "              cv2.cvtColor(img2,cv2.COLOR_GRAY2RGB))\n",
    "```\n",
    "![image.png](matching_and_ransac_files/att_00001.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-19T14:57:00.502490500Z"
    }
   },
   "outputs": [],
   "source": [
    "from local_descriptor import *\n",
    "from local_detector import *\n",
    "from matching import *\n",
    "from ransac import *\n",
    "\n",
    "\n",
    "timg1 = timg_load('v_woman1.ppm', True)/255.\n",
    "timg2 = timg_load('v_woman6.ppm', True)/255.\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    keypoint_locations1, descs1, A1 = detect_and_describe(timg1)\n",
    "    keypoint_locations2, descs2, A2 = detect_and_describe(timg2)\n",
    "    match_idxs, vals = match_smnn(descs1, descs2, 0.85) \n",
    "    tentative_matches = tentatives_to_opencv(match_idxs, vals)\n",
    "    pts_matches = torch.cat([A1[match_idxs[:,0],:2,2], A2[match_idxs[:,1],:2,2]], dim=1)\n",
    "    H, inl = ransac_h(pts_matches, 4.0, 0.99, 10000)\n",
    "\n",
    "draw_matches(kps1, kps2, tentative_matches,\n",
    "             H.detach().cpu().numpy(),\n",
    "             H_gt,\n",
    "             inl.cpu().numpy(),\n",
    "             cv2.cvtColor(img1,cv2.COLOR_GRAY2RGB),\n",
    "             cv2.cvtColor(img2,cv2.COLOR_GRAY2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference solution \n",
    "\n",
    "```python\n",
    "from local_descriptor import *\n",
    "from local_detector import *\n",
    "from matching import *\n",
    "from ransac import *\n",
    "\n",
    "\n",
    "timg1 = timg_load('v_woman1.ppm', True)/255.\n",
    "timg2 = timg_load('v_woman6.ppm', True)/255.\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    keypoint_locations1, descs1, A1 = detect_and_describe(timg1)\n",
    "    keypoint_locations2, descs2, A2 = detect_and_describe(timg2)\n",
    "    match_idxs, vals = match_smnn(descs1, descs2, 0.85) \n",
    "    tentative_matches = tentatives_to_opencv(match_idxs, vals)\n",
    "    pts_matches = torch.cat([A1[match_idxs[:,0],:2,2], A2[match_idxs[:,1],:2,2]], dim=1)\n",
    "    H, inl = ransac_h(pts_matches, 4.0, 0.99, 10000)\n",
    "\n",
    "draw_matches(kps1, kps2, tentative_matches,\n",
    "             H.detach().cpu().numpy(),\n",
    "             H_gt,\n",
    "             inl.cpu().numpy(),\n",
    "             cv2.cvtColor(img1,cv2.COLOR_GRAY2RGB),\n",
    "             cv2.cvtColor(img2,cv2.COLOR_GRAY2RGB))\n",
    "```\n",
    "![image.png](matching_and_ransac_files/att_00002.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
